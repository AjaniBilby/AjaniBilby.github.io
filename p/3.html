<head><title>Relational Table DBMS</title><meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="theme-color" content="#24292e">

<link rel="stylesheet" type="text/css" href="/style/main.css">
<link rel="stylesheet" type="text/css" href="/style/head.css">
<link rel="stylesheet" type="text/css" href="/style/footer.css">
<link rel="stylesheet" type="text/css" href="/style/article.css">
<link rel="stylesheet" type="text/css" href="/style/snippet.css"></head><body><header>
  <a href="/index.html">Home</a>
  <a href="/p/me.html" style="float: right;">Ajani James Bilby</a>
</header><div class="wrapper"><h1>Relational Table DBMS</h1><p>
<b>Recommended:</b> <a href="/p/1.html">UTF-8 Encoding</a>; <a href="/p/2.html">Two's Complement Integer</a></p><blockquote><p>This article will not be discussing;<ul><li>Data Encryption</li><li>Data replecation / distribution</li><li>Query Languages</li><li>Sorting</li><li>Caching</li><li>Data Conflict resolution</li><li>Optimizing disk read writes</li></ul></p><p>
Since they are all just extra layers of processing on top of what is discussed here, and it can be discussed separately
</p></blockquote><p>
Tables are essentially just a list of tuples (aka records, or rows), of which are stored into a file. However, tables appear to be 2D how does one store it into a linear file.</br>
First of all, we need to break down a table into it's components.</p><break></break><a name="Attributes"><h2>Attributes</h2></a><p>
These are the individual fields of a table. They are of set size and length of which makes our job of converting the dataset into a file much easier.</br>
Since we know the length of each attribute we can literally  just store them one after another, and then read back just the bytes of which belong to each attribute as they are needed.</p><p>
Below is an example of finding the slice points to get a specific attribute within an entire row.
<code><span class="typ">let</span>&nbspstart&nbsp<span class="kwd">=</span>&nbsp<span class="lit">0</span>;&nbsp<span class="com">//&nbspIn&nbspBytes</span><br><span class="typ">let</span>&nbspend&nbsp<span class="kwd">=</span>&nbsp<span class="lit">0</span>;&nbsp&nbsp&nbsp<span class="com">//&nbspIn&nbspBytes</span><br><br><span class="kwd">for</span>&nbsp(Attr&nbsp<span class="kwd">in</span>&nbspAttributes){<br>&nbsp&nbspend&nbsp<span class="kwd">+</span><span class="kwd">=</span>&nbspAttr.size;<br><br>&nbsp&nbsp<span class="kwd">if</span>&nbsp(Attr.name&nbsp<span class="kwd">=</span><span class="kwd">=</span>&nbspfield){<br>&nbsp&nbsp&nbsp&nbsp<span class="kwd">break</span>;<br>&nbsp&nbsp}<br><br>&nbsp&nbspstart&nbsp<span class="kwd">=</span>&nbspend;<br>}</code></p><break></break><a name="Data Types"><h3>Data Types</h3></a><p>
Some common table data types and their sizes.<ul><li><b>Float</b>: A signed number of which can include non-whole numbers. Made up of 32Bits</li><li><b>Double</b>: A signed number of which can include non-while numbers as well as number impractical to be stored as ints <code inline="true">6*(10)^(56)</code>. Made up of 64bits</li><li><b>String</b>: An array of characters</li><li><b>Int</b>: An Integer value encoded using two's complement integer</li><ul><li><b>Int8</b>: An integer made up of 8 bits</li><li><b>Int16</b>: An integer made up of 16bits</li><li><b>Int32</b>: An integer made up of 32bits</li><li><b>Int64</b>: An integer made up of 64bits</li></ul><li><b>UInt</b>: A positive only integer value</li><ul><li><b>UInt8</b>: An unsigned integer made up of 8 bits</li><li><b>UInt16</b>: An unsigned integer made up of 16bits</li><li><b>UInt32</b>: An unsigned integer made up of 32bits</li><li><b>UInt64</b>: An unsigned integer made up of 64bits</li></ul><li><b>Boolean</b>: A true/false value of which takes up a whole byte since it is in the smallest division of useable storage space.</li><li><b>Date</b>: The method of storing dates can vary from system to system. You could encode your dates using 32bit ints and UNIX time, or you could use a string and storing it using <a href="https://en.wikipedia.org/wiki/ISO_8601">ISO 8601</a></li></ul></p><break></break><a name="Tuples"><h2>Tuples</h2></a><p>
Since we now know how to read attributes from a tuple, we can use a similar approach to read a tuple from a table.</br>
First of all, we need to find the size of each tuple
<code><span class="typ">let</span>&nbsptupleSize&nbsp<span class="kwd">=</span>&nbsp<span class="lit">0</span>;<br><span class="kwd">for</span>&nbsp(<span class="typ">let</span>&nbspAttr&nbsp<span class="kwd">in</span>&nbspAttributes){<br>&nbsp&nbsptupleSize&nbsp<span class="kwd">+</span><span class="kwd">=</span>&nbspAttr.size;<br>}</code></p><p>
Now we can read the tuple in the exact same way</p><break></break><a name="Primary and Composite Keys"><h2>Primary and Composite Keys</h2></a><p>
Keys are a way of uniquely identifying individual rows.</br>
A primary key is a single attribute of which is unique for every row within the table (i.e. ID).</br>
A composite key is when multiple fields in combination are used to uniquely identify a row (i.e. First & Given Name).</br>
Both of these key systems can be implemented in multiple ways.</p><a name="Depth Key"><h3>Depth Key</h3></a><p>
This is a simple approach where the system reads just the key values of each row until it finds a match with the request, then it returns the whole row.</br>
Thus, the time taken to find a given tuple increases linearly.</p><a name="Key Hashing"><h3>Key Hashing</h3></a><p>
The concept of <a href="/p/4.html">Key Hashing</a> is to convert a given value into a unique number (i.e. James => 1; Bob => 2),</br>
this means that you can hash a given key to then get the index of the row belonging to that key.</br>
Thus, this method can vastly improve the time it takes to get data from the table since it does not need to scan each tuple to see if it's key matches.</br>
However, no hashing algorithm is perfect and there will be trade-offs for speed to performance, because you will end up with empty indexes between the data of which you have stored.</br></p><blockquote><p>I.E. if you hash 'Bob' => 3; and 'Sally' => 54 that they are the only people in your database you can see that you will now need to store index 1-2 & 4-53 to ensure that the hashing algorithm points to the correct tuple.
</p></blockquote><p>Since you always use this hashing function to get the index then just read of the index the time taken to read a row is always a constant value, thus being optimal for large databases where size limitations are not as much of an issue.</p><break></break><a name="Referencing"><h2>Referencing</h2></a><p>
This allows data to be connected almost directly to allow the storing of more complex data.</br>
For instance instead of storing a client's address with every online order they make you can instead just store the client ID as a reference then read the address form the client table.</p><a name="Key Referencing"><h3>Key Referencing</h3></a><p>
Uses the systems previously described to find the target row.</br></p><blockquote><p>If it is a Composite key then you will need to store all key values for the reference to work.
</p></blockquote><a name="Exact Referencing"><h3>Exact Referencing</h3></a><p>
Instead of needing to re-find the target row every time, the reference is the exact index of the row. Thus, no extra processing is required to find the target tuple, instead it can just be read off.</p><break></break><a name="Compacting a Table"><h2>Compacting a Table</h2></a><p>
This task removes any empty rows from the database one after another to decrease the size of the table. This operation while space effective will take time, and during processing no data can relyably be read or written to the table for fear or corruption. Thus, it is a highly expensive processing task.</br>
Also, if you are using Key Hashing or Exact Referencing for performance speed ups it will break the entire system reading incorrect tuples, and even possibly attempting to read out of the table it's self.</br>
Thus, it has become a rather out-dated practise only ever really used of archives or personal small scale databases.</p><a name="Foot Note"><h2>Foot Note</h2></a><p>
Since entire tables can be bigger than the RAM of a single computer all modern DBMSs never read the whole table at once. Instead they read it as a stream of data.</br>
For instance, you have an input buffer, you pipe all of your data from your read stream into that, then once you have enough data to make up a tuple, you remove that first tuple amount of data from the buffer and run your operation on it, then you can pipe your result to another file.</br>
Thus, you can now work with massive datasets, and have massive query results. Now when your operation is done you can just pipe that entire output file to where your result needs to go.</br>
Also, it is important to know that this output cache file is not necessary, for instance you could instead write directly to a table or pipe your results back to what ever requested the event in the first place.</p><break></break><a name="References"><h2>References</h2></a><p><ol><li>Information Processes and Technology (The HSC Course) - Samuel Davis</li><li><a href="http://www.infocobuild.com/education/audio-video-courses/computer-science/CS186-Spring2015-Berkeley/lecture-01.html">CS186 Berkeley - Lecture 1</a></li></ol></p><span class="tags"><h6 style="display: inline-block;">Tags:</h6><a href="/t/Data-Structure.html"><tag>Data-Structure;</tag></a><a href="/t/IPT.html"><tag>IPT;</tag></a></span></article></div><footer>
  <a href="https://goo.gl/forms/8wgwU9mPZlKogDEn2">Feedback</a>
  <a href="/feed.rss" style="float:right">RSS Feed</a>
</footer></body>